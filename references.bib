@article{bluteDifferentialCategories2006,
  title = {Differential {{Categories}}},
  author = {Blute, R.F. and Seely, R.A.G. and Cockett, J.R.B.},
  date = {2006},
  journaltitle = {Mathematical Structures in Computer Science}
}

@unpublished{cockettReverseDerivativeCategories2019,
  title = {Reverse Derivative Categories},
  author = {Cockett, Robin and Cruttwell, Geoffrey and Gallagher, Jonathan and Lemay, Jean-Simon Pacaud and MacAdam, Benjamin and Plotkin, Gordon and Pronk, Dorette},
  date = {2019-10-15},
  eprint = {1910.07065},
  eprinttype = {arXiv},
  eprintclass = {cs, math},
  url = {http://arxiv.org/abs/1910.07065},
  urldate = {2024-07-10},
  abstract = {The reverse derivative is a fundamental operation in machine learning and automatic differentiation [1, 11]. This paper gives a direct axiomatization of a category with a reverse derivative operation, in a similar style to that given by [2] for a forward derivative. Intriguingly, a category with a reverse derivative also has a forward derivative, but the converse is not true. In fact, we show explicitly what a forward derivative is missing: a reverse derivative is equivalent to a forward derivative with a dagger structure on its subcategory of linear maps. Furthermore, we show that these linear maps form an additively enriched category with dagger biproducts.},
  langid = {english},
  keywords = {Computer Science - Logic in Computer Science,D.3.1,F.3.2,Mathematics - Category Theory},
  file = {/home/frc/Zotero/storage/FILS3YV2/Cockett et al. - 2019 - Reverse derivative categories.pdf}
}

@article{cruttwellDeepLearningParametric,
  title = {Deep {{Learning}} with {{Parametric Lenses}}},
  author = {Cruttwell, Geoffrey S H and Gavranovic, Bruno and Ghani, Neil and Wilson, Paul and Zanasi, Fabio},
  abstract = {We propose a categorical semantics for machine learning algorithms in terms of lenses, parametric maps, and reverse derivative categories. This foundation provides a powerful explanatory and unifying framework: it encompasses a variety of gradient descent algorithms such as ADAM, AdaGrad, and Nesterov momentum, as well as a variety of loss functions such as MSE and Softmax cross-entropy, and different architectures, shedding new light on their similarities and differences. Furthermore, our approach to learning has examples generalising beyond the familiar continuous domains (modelled in categories of smooth maps) and can be realised in the discrete setting of Boolean and polynomial circuits. We demonstrate the practical significance of our framework with an implementation in Python.},
  langid = {english},
  file = {/home/frc/Zotero/storage/VIM2JFIN/Cruttwell et al. - Deep Learning with Parametric Lenses.pdf}
}

@unpublished{rileyCategoriesOptics2018,
  title = {Categories of {{Optics}}},
  author = {Riley, Mitchell},
  date = {2018-09-07},
  eprint = {1809.00738},
  eprinttype = {arXiv},
  eprintclass = {math},
  url = {http://arxiv.org/abs/1809.00738},
  urldate = {2024-07-21},
  abstract = {Bidirectional data accessors such as lenses, prisms and traversals are all instances of the same general ‘optic’ construction. We give a careful account of this construction and show that it extends to a functor from the category of symmetric monoidal categories to itself. We also show that this construction enjoys a universal property: it freely adds counit morphisms to a symmetric monoidal category. Missing in the folklore is a general definition of ‘lawfulness’ that applies directly to any optic category. We provide such a definition and show that it is equivalent to the folklore profunctor optic laws.},
  langid = {english},
  keywords = {Mathematics - Category Theory},
  file = {/home/frc/Zotero/storage/P6J4DXDK/Riley - 2018 - Categories of Optics.pdf}
}

@unpublished{shieblerCategoryTheoryMachine2021,
  title = {Category {{Theory}} in {{Machine Learning}}},
  author = {Shiebler, Dan and Gavranović, Bruno and Wilson, Paul},
  date = {2021-06-13},
  eprint = {2106.07032},
  eprinttype = {arXiv},
  eprintclass = {cs},
  url = {http://arxiv.org/abs/2106.07032},
  urldate = {2024-07-10},
  abstract = {Over the past two decades machine learning has permeated almost every realm of technology. At the same time, many researchers have begun using category theory as a unifying language, facilitating communication between different scientific disciplines. It is therefore unsurprising that there is a burgeoning interest in applying category theory to machine learning. We aim to document the motivations, goals and common themes across these applications. We touch on gradient-based learning, probability, and equivariant learning.},
  langid = {english},
  keywords = {Computer Science - Machine Learning},
  file = {/home/frc/Zotero/storage/3QPN9TYT/Shiebler et al. - 2021 - Category Theory in Machine Learning.pdf}
}

@article{wilsonReverseDerivativeAscent2021a,
  title = {Reverse {{Derivative Ascent}}: {{A Categorical Approach}} to {{Learning Boolean Circuits}}},
  shorttitle = {Reverse {{Derivative Ascent}}},
  author = {Wilson, Paul and Zanasi, Fabio},
  date = {2021-02-08},
  journaltitle = {Electronic Proceedings in Theoretical Computer Science},
  shortjournal = {Electron. Proc. Theor. Comput. Sci.},
  volume = {333},
  pages = {247--260},
  issn = {2075-2180},
  doi = {10.4204/EPTCS.333.17},
  url = {http://arxiv.org/abs/2101.10488v1},
  urldate = {2024-07-21},
  langid = {english},
  file = {/home/frc/Zotero/storage/VKR7JTU5/Wilson and Zanasi - 2021 - Reverse Derivative Ascent A Categorical Approach .pdf}
}
